# Cloth Simulation

The Cloth Simulation is a project that implements real-time simulation of a cloth using a point mass and spring based system. There were many developments made in order to create a cloth stimulation with realistic rendering:

First, using the Xcode IDE and writing in C++, my partner and I built the data structures to discretely represent a sheet of cloth by dividing the cloth up into evenly spaced point masses and connecting nearby masses with springs. Then, we defined and applied physical constraints on each point mass of the cloth, and applied numerical integration to simulate the way the cloth moves over time.
 
Next, we applied cloth collision with other objects in the scene (such as spheres and planes) as well as self-collisions to prevent cloth clipping. As a result, if there is a scene in which the cloth falls on an object, the cloth will not pass through the object or behave strangely (such as bouncing off the object). Instead it will lay on the object, and slowly (and naturally) slide off over time. Also, if there is a scene in which the cloth falls and folds on itself, the cloth will not clip through itself or behave strangely (such as continuously bouncing off of itself). 

Finally, we wrote a few GLSL shader programs to give the cloth color and texture. We implemented <i>diffuse</i> shading,<i>Blinn-Phong</i> shading (which gives the cloth a realistic shine), <i>texture mapping</i> (which basically “wraps” a 2D picture onto the surface of a 3D object), <i>bump mapping</i> (which gives the illusion of detail, such as bumps, on the object by modifying the normal vectors of the object), <i>displacement mapping<i> (where we change the vectors of the object - thus changing the geometry of the object itself - and modify the normals so that the cloth looks wrinkled/jagged ), and <i>environment-mapped reflections</i> (where we sample from an environment map’s incoming light rays - say the environment map was of based on a picture of the Golden Gate Bridge - and reflect it off the object’s surface).

 To learn more about this process, please visit the html or pdf version of the document named "<b><i>Cloth Simulation Walk-Through & Results.html</i></b>".

After implementing a cloth stimulation with realistic rendering, my project partner and I joined another group to delve further into creating a local shading model that makes cloth look more realistic and detailed to the human eye (instead of the plastic-like material it had before). In this new group, I researched existing papers that tackled this problem, and used those as references to create local shading models that focuses specifically (and is more fit for) textile materials.

 We did this by implementing <b>two new shaders</b> that work as modified microfacet models with 3 main components: normal distribution, visibility, and diffusion. We used the same structure as the Blinn-Phong model (which uses ambient, diffused, and specular lighting). The <b>first</b> shader, called the cloth shader, focused more on textiles that have more roughness or texture to them - such as denim and wool-knot material. The <b>second</b> shader, the anisotropic shader, focused more on clothing that is more sleek and has more sheen to it - such as silk and velvet. Lastly, we set the density and spring constant values for each material so that the behavior would match the material correctly. For example, since denim is a denser material (than say silk), we set high values for the spring and density constants so that the cloth looks stiffer and is heavier as it falls onto a sphere.
 
 To learn more about this process, please visit the html or pdf version of the document named "<b><i>SilkySmooth Simulation</i></b>".
